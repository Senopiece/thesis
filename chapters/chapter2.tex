\chapter{Literature Review}
\label{chap:lr}
\chaptermark{Literature Review}

\section{sEMG-Based Hand Pose Estimation}

Surface electromyography (sEMG) is widely used to estimate hand gestures and joint angles by measuring electrical activity from forearm muscles \cite{oskoei2007myoelectric, simao2019review}. Traditional approaches often use handcrafted features (e.g., mean absolute value, waveform length, or zero crossings) followed by classifiers such as support vector machines (SVM) or multilayer perceptrons (MLP) \cite{oladazimi2012review, liu2007recognition}. However, these methods typically lack robustness to motion complexity and signal variability \cite{parajuli2019real}. Moreover, the development of effective handcrafted features often requires domain-specific knowledge and extensive manual tuning by qualified specialists, which inherently limits generalizability and scalability across different tasks and user populations \cite{atzori2016deep, oskoei2008support, phinyomark2018feature}.

Recent work has focused on deep learning models, such as convolutional neural networks (CNNs), recurrent neural networks (RNNs), and temporal convolutional networks (TCNs) \cite{ameri2019regression, briouza2021convolutional, zhang2023lstm}, which can automatically extract and model temporal features from raw or minimally processed sEMG signals. These models show improved accuracy over traditional pipelines but still rely on fixed temporal windows and often ignore inter-channel dependencies \cite{lee2022explainable}.

In response, several researchers have explored attention-based and adaptive models, enabling selective focus on more informative regions of the signal \cite{yang2025stcnet, hu2019semg}. Yet, few works explicitly address the simultaneous adaptation in both time and channel space. Our proposed approach, termed \textit{Spatiotemporal Sampling}, aims to fill this gap by learning a sampling window and spatial activation pattern jointly from the data.

\section{Multimodal sEMG Datasets}

A number of public datasets have been developed for training and benchmarking sEMG-based models. The \textbf{NinaPro} dataset family is among the most widely used, offering synchronized sEMG and kinematic glove data for a variety of gestures \cite{zia2018multiday}. While valuable, NinaPro focuses on short, predefined movements and generalization across subjects, which makes it less suited for intra-subject studies involving longer, continuous sessions.

The \textbf{EMG2Pose} dataset introduced a large-scale, high-resolution multimodal dataset for fine-grained pose regression \cite{salter2024emg2pose}. It includes synchronized 3D motion capture and EMG recordings, offering unprecedented quality. However, the system setup involves 26 professional OptiTrack cameras and high-end Delsys sensors, resulting in a prohibitively expensive configuration for most academic labs. Notably, EMG2Pose and other successful works in continuous hand tracking consistently use high-fidelity acquisition setups, typically recording sEMG at sampling rates of 2kHz with at least 12-bit resolution \cite{salter2024emg2pose, zanghieri2023semg, lee2022explainable}. These parameters are critical to preserve fine-grained muscle activation patterns and temporal precision required for accurate joint angle estimation. As a result, this configuration has become the de facto standard in the field for high-resolution EMG-to-pose applications.

At the other end of the spectrum, several low-cost or DIY setups exist, often based on consumer-grade devices like the Myo armband or custom EMG acquisition boards (e.g., based on Arduino or ADS1299 ICs) \cite{nasri2020semg}. These systems typically suffer from limitations such as:
\begin{itemize}
    \item Insufficient sampling rates (e.g., below 12bit 2kHz),
    \item Lack of synchronized, continuous hand tracking at 30,fps or higher \cite{graf2023combining},
\end{itemize}

\section{3D Hand Tracking with MediaPipe}

MediaPipe has emerged as a robust and accessible framework for 3D hand tracking, gaining traction in both academic and applied research domains. It offers real-time, markerless tracking using standard RGB cameras and supports a wide range of deployment configurations due to its platform-agnostic architecture. Unlike commercial alternatives such as Leap Motion and VR headsets, which are limited by proprietary hardware and fixed interaction volumes, MediaPipe enables \textit{unbounded spatial scaling}, making it ideal for flexible experimental setups.

Several studies have validated the accuracy and robustness of MediaPipe in diverse scenarios. For instance, \cite{reimer2023evaluation} demonstrated that MediaPipe maintains stable tracking performance up to 2.75 meters, outperforming Oculus Quest and Leap Motion in multi-user and large-scale environments. In comparative tests on finger joint angle tracking, MediaPipe achieved a lower root mean square error (RMSE) of 10.9\textdegree{} versus 14.7\textdegree{} for Leap Motion, highlighting its superior precision in kinematic analysis \cite{maggioni2025optimisation}. Moreover, its adoption in recent deep learning pipelines for sEMG-based gesture recognition further underscores its suitability for high-quality data acquisition \cite{lee2022explainable}.

These advantages make MediaPipe an increasingly attractive alternative to traditional motion tracking systems, particularly in domains requiring scalable, cost-effective, and accurate 3D hand pose estimation.

\section{Deep Learning Models for EMG-to-Pose Estimation}

Early deep learning approaches demonstrated the effectiveness of CNNs and RNNs for \textit{sEMG}-based hand gesture recognition. For example, Briouza et al.\ \cite{briouza2021convolutional} designed a shallow 1D CNN that achieved high accuracy on the Ninapro DB2 benchmark (49 gestures across 40 subjects). More recently, Zhang et al.\ \cite{zhang2023lstm} proposed an LSTM with dual-stage attention (LSTM-MSA) that outperformed prior models on multiple EMG datasets, yielding superior F1-scores, accuracy, recall, and precision. These works highlight that temporal context and learned feature attention can markedly improve sEMG decoding performance. Moving from classification to \textit{continuous pose estimation}, several models have been developed to map sEMG signals to detailed hand kinematics.

\textbf{VEMG2Pose} -- introduced with the EMG2Pose dataset -- adopts a velocity-based prediction strategy \cite{salter2024emg2pose}. It uses a time-depth separable CNN encoder (for parameter-efficient feature extraction) followed by an LSTM decoder that regresses angular velocities from sEMG and integrates them over time into joint angles. This autoregressive formulation enforces temporal smoothness and mitigates drift. Despite a moderate model size (the separable convolution layers and LSTM have on the order of millions of parameters, comparable to the other baselines), VEMG2Pose achieves state-of-the-art accuracy. In the EMG2Pose benchmark`s most challenging setting (unseen users and unseen motion stages), it attained the lowest mean fingertip \textit{landmark error} at \textbf{21.6 \textpm 2.0mm}, significantly outperforming NeuroPose (24.9 \textpm 1.7mm) and SensingDynamics (27.2 \textpm 2.0mm) under the same conditions. Its mean joint-angle error in that scenario was 15.8$^\circ$, versus 17.5$^\circ$ and 18.7$^\circ$ for the others. VEMG2Pose also led in easier generalization tasks (e.g., training on all motions but new users), demonstrating the benefit of dynamic velocity decoding for cross-user robustness. Notably, it was trained on the new EMG2Pose dataset -- by far the largest of its kind with \textbf{193 subjects and 370 hours} of sEMG-motion data -- which likely helped the model generalize better across individuals and gestures.

\textbf{NeuroPose}, in contrast, performs direct regression of joint angles using a U-Net style architecture with residual bottleneck layers. A convolutional encoder first spatially and temporally downsamples the multi-channel sEMG, extracting features that are refined via residual blocks; a decoder then upsamples these features to predict joint angles at the original frequency. Originally, Liu et al.\ (2021) trained it on a smaller dataset (an 8-channel Myo armband, 12 users) by leveraging anatomical finger motion constraints and transfer learning for new users. The model yielded a median \textit{angular error} of about \textbf{6.24$^\circ$} (90th percentile 18.3$^\circ$) in user-specific tests and was efficient enough for real-time use on a smartphone with ~0.1s latency. To improve interpretability, recent variants incorporate attention mechanisms: for example, Lee et al.\ \cite{lee2022explainable} added an explainable channel-wise attention module to highlight which sensor signals influence each predicted finger angle. This kind of saliency analysis reveals consistent patterns (e.g., specific EMG sensors strongly activate for particular finger movements), lending insight into the model`s decisions. In the EMG2Pose benchmark, our re-implementation of NeuroPose was trained from scratch on the larger 16-channel dataset. It performed competitively, but with higher errors than VEMG2Pose -- for instance, \textasciitilde{}\textbf{24.9mm} fingertip error in the hardest unseen-user scenario (about 15\% worse than VEMG2Pose). NeuroPose`s direct angle regression approach benefits from a complex encoder--decoder (on the order of a few million parameters) and produces smooth results (the original included a temporal smoothing regularizer), but it may generalize less well to new users without additional adaptation.

\textbf{SensingDynamics} represents another design point, using a \textit{high-density EMG} approach and a lightweight network. S\^impetru et al.\ (2022) collected data from a \textit{320-electrode} forearm EMG array (spread over 5 patches) in 13 participants. Their model employs a custom 3D convolutional encoder to handle the 320-channel spatio-temporal input, and a 3-layer MLP decoder that outputs hand joint angles, keypoint positions, and even grip force. In their report, this system could \textit{``sense the full dynamics''} of the hand, achieving very low tracking error in within-subject evaluations (e.g., on the order of only \textbf{3mm} positional MAE for fingertip locations). The original SensingDynamics architecture was tailored to the high-density setup -- including special layers like learnable synthetic muscle unit (SMU) activations to mimic motor unit behavior, 3D convolutions spanning electrode patches, and an additional low-pass filtered EMG input branch to improve noise robustness. Even with modifications, SensingDynamics remained the most compact model (its parameter count is relatively small, since it uses only a few conv layers and a small MLP). This compactness, however, came at some cost to accuracy on the large benchmark. SensingDynamics exhibited higher errors than the other two baselines in cross-user tests -- for example, about \textbf{27.2mm} mean fingertip error in the unseen-user-and-stage condition. Its simpler architecture struggled to capture the full complexity of signals when generalized broadly, despite performing well on its original per-user high-density data.

All the above models were evaluated under a common framework in the EMG2Pose study, after training on the large-scale benchmark dataset (\textasciitilde{}80 million frames from 193 people). The results underscore several points: (1) modeling \textit{temporal dynamics} explicitly (as VEMG2Pose does) can improve smoothness and accuracy of pose predictions, (2) sufficient model capacity and training data are critical for generalization -- the high-density SensingDynamics achieved excellent accuracy on limited data (per-user) but was outperformed on a broad dataset, and (3) \textit{interpretability mechanisms} (as seen in NeuroPose variants) are increasingly important for understanding and improving EMG-to-pose mappings. Building on these insights, our work incorporates adaptive spatio-temporal selection mechanisms that learn to emphasize the most informative signal components for each instance, aiming to further improve intra-user generalization and enhance the robustness of EMG--pose decoding.

\section{Research Gap}

From the review above, two major gaps emerge:
\begin{enumerate}
    \item \textbf{Modeling:} Few works jointly learn where (in time) and what (in channel space) to attend to in sEMG signals. Most deep models use fixed-length windows and treat all channels equally. The concept of learned \textit{spatiotemporal sampling} remains largely unexplored in sEMG modeling.
    \item \textbf{Data Acquisition:} There is no publicly available, cost-effective dataset acquisition system that provides both high-frequency sEMG data and synchronized 3D hand tracking at sufficient frame rates \cite{seo2024posture}.
\end{enumerate}

This thesis addresses both gaps: by proposing a model that learns to extract informative spatiotemporal segments from EMG, and by building a custom synchronized EMG+vision capture system that balances affordability and data fidelity.